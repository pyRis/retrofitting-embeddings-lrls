# first step parameters
## number of tokens in the training vocabulary
vocab_size: 200000
## size of the context window
window_size: 10
## the number of paritions to divide cooccurence matrix in 
num_partitions: 10
## chunk size of Dataset
chunk_size: 1000000

# when used in first step, specify the output directory of cooccurrence entries
# when used in second step, specify where to read cooccurrence entries from
cooccurrence_dir: output/cooccurrence

# second step parameters
## output path for the trained word vectors 
output_filepath: output/embeddings.pt
## pytorch training parameters
batch_size: 4096
num_epochs: 100
device: cuda
learning_rate: 0.05
## glove paremeters
embedding_size: 300
x_max: 100
alpha: 0.75
